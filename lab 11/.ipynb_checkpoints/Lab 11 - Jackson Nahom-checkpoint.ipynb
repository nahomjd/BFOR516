{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fee567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment import vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b626310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0         PRES  TURN_AT_TALK          CEO    WORDCOUNT  \\\n",
      "count  1114.000000  1114.000000   1114.000000  1114.000000  1114.000000   \n",
      "mean    556.500000     0.581688     15.447935     0.793537    18.205566   \n",
      "std     321.728405     0.493504     19.025057     0.404949     8.940149   \n",
      "min       0.000000     0.000000      2.000000     0.000000     1.000000   \n",
      "25%     278.250000     0.000000      3.000000     1.000000    12.000000   \n",
      "50%     556.500000     1.000000      4.000000     1.000000    17.000000   \n",
      "75%     834.750000     1.000000     24.000000     1.000000    23.000000   \n",
      "max    1113.000000     1.000000     93.000000     1.000000    62.000000   \n",
      "\n",
      "       Restatement Topic        FRAUD  \n",
      "count        1114.000000  1114.000000  \n",
      "mean            0.176840     0.352783  \n",
      "std             0.381705     0.636108  \n",
      "min             0.000000     0.000000  \n",
      "25%             0.000000     0.000000  \n",
      "50%             0.000000     0.000000  \n",
      "75%             0.000000     1.000000  \n",
      "max             1.000000     2.000000  \n"
     ]
    }
   ],
   "source": [
    "call_data = pd.read_csv('data/earningscall_fraud.csv')\n",
    "\n",
    "print(call_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b6a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17684021543985637\n"
     ]
    }
   ],
   "source": [
    "# percent of fraud\n",
    "print(call_data['Restatement Topic'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "795621f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence      Welcome to Northwest Pipe's conference call an...\n",
      "clean_text    [welcom, northwest, pipe, confer, announc, ear...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim import corpora\n",
    "\n",
    "call_data['clean_text'] = call_data['Sentence'].apply(preprocess_string)\n",
    "print(call_data.loc[1, ['Sentence', 'clean_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2ae3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1116 unique tokens: ['diann', 'thank', 'announc', 'confer', 'earn']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(call_data['clean_text'])\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e72de9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in call_data['clean_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b09501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "lda_10 = models.LdaModel(bow_corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27c0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.018*\"look\" + 0.018*\"expect\" + 0.017*\"project\" + 0.015*\"like\" + 0.014*\"quarter\" + 0.013*\"demand\" + 0.012*\"impact\" + 0.012*\"time\" + 0.011*\"signific\" + 0.010*\"date\"\n",
      "Topic 1 : 0.034*\"cost\" + 0.026*\"steel\" + 0.020*\"quarter\" + 0.020*\"price\" + 0.016*\"product\" + 0.015*\"busi\" + 0.015*\"chang\" + 0.013*\"higher\" + 0.012*\"result\" + 0.010*\"materi\"\n",
      "Topic 2 : 0.051*\"think\" + 0.033*\"million\" + 0.030*\"quarter\" + 0.018*\"time\" + 0.016*\"fourth\" + 0.015*\"cost\" + 0.014*\"year\" + 0.014*\"abl\" + 0.013*\"increas\" + 0.011*\"expens\"\n",
      "Topic 3 : 0.027*\"quarter\" + 0.022*\"project\" + 0.018*\"littl\" + 0.018*\"water\" + 0.015*\"price\" + 0.014*\"bit\" + 0.013*\"expect\" + 0.013*\"think\" + 0.012*\"fourth\" + 0.012*\"go\"\n",
      "Topic 4 : 0.021*\"cost\" + 0.016*\"steel\" + 0.014*\"share\" + 0.014*\"market\" + 0.013*\"lower\" + 0.012*\"year\" + 0.012*\"sell\" + 0.012*\"margin\" + 0.012*\"price\" + 0.011*\"million\"\n",
      "Topic 5 : 0.036*\"quarter\" + 0.031*\"product\" + 0.028*\"million\" + 0.016*\"project\" + 0.015*\"market\" + 0.014*\"tubular\" + 0.013*\"steel\" + 0.013*\"busi\" + 0.011*\"expect\" + 0.010*\"compar\"\n",
      "Topic 6 : 0.042*\"quarter\" + 0.041*\"million\" + 0.026*\"revenu\" + 0.024*\"year\" + 0.016*\"compar\" + 0.015*\"think\" + 0.014*\"water\" + 0.013*\"market\" + 0.011*\"better\" + 0.011*\"price\"\n",
      "Topic 7 : 0.032*\"quarter\" + 0.030*\"expect\" + 0.023*\"product\" + 0.017*\"time\" + 0.015*\"million\" + 0.015*\"bid\" + 0.014*\"steel\" + 0.013*\"year\" + 0.012*\"project\" + 0.010*\"job\"\n",
      "Topic 8 : 0.055*\"million\" + 0.038*\"year\" + 0.033*\"quarter\" + 0.021*\"expect\" + 0.019*\"sale\" + 0.016*\"increas\" + 0.013*\"continu\" + 0.013*\"compar\" + 0.011*\"product\" + 0.011*\"cost\"\n",
      "Topic 9 : 0.026*\"product\" + 0.024*\"quarter\" + 0.021*\"project\" + 0.019*\"year\" + 0.015*\"cost\" + 0.015*\"expect\" + 0.013*\"group\" + 0.012*\"increas\" + 0.011*\"second\" + 0.010*\"tubular\"\n"
     ]
    }
   ],
   "source": [
    "for topic in lda_10.show_topics():\n",
    "    print(\"Topic\", topic[0], \":\", topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b554e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -6.905256194913186\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', lda_10.log_perplexity(bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da3afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -6.729851155165351\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "coherence_model_lda = CoherenceModel(model=lda_10, texts=call_data['clean_text'], dictionary=dictionary, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b912aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "with open('data/stoplist.txt', 'r') as f:\n",
    "    stopwords = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2d843ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\" preprocess string and remove words from custom stopword list. \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for word in preprocess_string(text):\n",
    "        if word not in stopwords:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "call_data['clean_newstop'] = call_data['Sentence'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d78a7f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1001 unique tokens: ['diann', 'announc', 'confer', 'earn', 'northwest']...)\n"
     ]
    }
   ],
   "source": [
    "new_dictionary = corpora.Dictionary(call_data['clean_newstop'])\n",
    "print(new_dictionary)\n",
    "\n",
    "new_corpus = [new_dictionary.doc2bow(text) for text in call_data['clean_newstop']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a912c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.045*\"steel\" + 0.021*\"ton\" + 0.014*\"overal\" + 0.014*\"probabl\" + 0.014*\"strong\" + 0.014*\"project\" + 0.012*\"backlog\" + 0.012*\"lower\" + 0.010*\"continu\" + 0.010*\"month\"\n",
      "Topic 1 : 0.019*\"signific\" + 0.015*\"steel\" + 0.015*\"project\" + 0.013*\"higher\" + 0.013*\"improv\" + 0.011*\"tubular\" + 0.011*\"probabl\" + 0.011*\"continu\" + 0.011*\"date\" + 0.009*\"construct\"\n",
      "Topic 2 : 0.031*\"result\" + 0.027*\"compar\" + 0.024*\"steel\" + 0.021*\"water\" + 0.018*\"transmiss\" + 0.016*\"materi\" + 0.013*\"group\" + 0.011*\"project\" + 0.011*\"caus\" + 0.011*\"rang\"\n",
      "Topic 3 : 0.034*\"backlog\" + 0.022*\"certainli\" + 0.020*\"project\" + 0.020*\"tubular\" + 0.015*\"brian\" + 0.015*\"month\" + 0.014*\"steel\" + 0.013*\"opportun\" + 0.013*\"fund\" + 0.013*\"bid\"\n",
      "Topic 4 : 0.022*\"tubular\" + 0.017*\"share\" + 0.015*\"project\" + 0.015*\"ye\" + 0.014*\"energi\" + 0.012*\"water\" + 0.012*\"steel\" + 0.010*\"lower\" + 0.010*\"result\" + 0.009*\"agenc\"\n",
      "Topic 5 : 0.039*\"group\" + 0.027*\"tubular\" + 0.021*\"gross\" + 0.020*\"profit\" + 0.019*\"activ\" + 0.018*\"compar\" + 0.016*\"signific\" + 0.013*\"stimulu\" + 0.013*\"gener\" + 0.012*\"water\"\n",
      "Topic 6 : 0.014*\"plant\" + 0.014*\"gener\" + 0.014*\"specif\" + 0.013*\"steel\" + 0.012*\"issu\" + 0.012*\"month\" + 0.011*\"late\" + 0.010*\"abl\" + 0.010*\"suppli\" + 0.010*\"demand\"\n",
      "Topic 7 : 0.020*\"water\" + 0.017*\"project\" + 0.016*\"continu\" + 0.013*\"steel\" + 0.013*\"improv\" + 0.011*\"bid\" + 0.011*\"gener\" + 0.010*\"net\" + 0.010*\"pipe\" + 0.010*\"addit\"\n",
      "Topic 8 : 0.030*\"tax\" + 0.023*\"adjust\" + 0.021*\"incom\" + 0.021*\"net\" + 0.014*\"compar\" + 0.014*\"water\" + 0.012*\"opportun\" + 0.012*\"ahead\" + 0.012*\"share\" + 0.012*\"report\"\n",
      "Topic 9 : 0.036*\"continu\" + 0.036*\"project\" + 0.023*\"water\" + 0.020*\"strong\" + 0.013*\"record\" + 0.013*\"differ\" + 0.012*\"transmiss\" + 0.010*\"improv\" + 0.010*\"believ\" + 0.009*\"steel\"\n"
     ]
    }
   ],
   "source": [
    "lda_new = models.LdaModel(new_corpus, num_topics=10, id2word=new_dictionary)\n",
    "\n",
    "for topic in lda_new.show_topics():\n",
    "    print(\"Topic\", topic[0], \":\", topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc4dc933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.050003044), (1, 0.050003044), (2, 0.050003044), (3, 0.050003044), (4, 0.050003044), (5, 0.050003044), (6, 0.050003044), (7, 0.54997265), (8, 0.050003044), (9, 0.050003044)]\n",
      "[(0, 0.014286468), (1, 0.014286224), (2, 0.014286485), (3, 0.014286732), (4, 0.014288322), (5, 0.014287145), (6, 0.87141764), (7, 0.014287321), (8, 0.014286282), (9, 0.014287413)]\n",
      "[(3, 0.93076515)]\n",
      "[(0, 0.0111124), (1, 0.0111117475), (2, 0.01111558), (3, 0.011112106), (4, 0.8999831), (5, 0.011113911), (6, 0.011111682), (7, 0.011114508), (8, 0.011111579), (9, 0.011113446)]\n",
      "[(2, 0.92499626)]\n",
      "[(0, 0.016669285), (1, 0.84996015), (2, 0.0166755), (3, 0.016674267), (4, 0.016669672), (5, 0.0166708), (6, 0.016669162), (7, 0.016670417), (8, 0.01667107), (9, 0.016669702)]\n",
      "[(0, 0.1), (1, 0.1), (2, 0.1), (3, 0.1), (4, 0.1), (5, 0.1), (6, 0.1), (7, 0.1), (8, 0.1), (9, 0.1)]\n",
      "[(0, 0.020003922), (1, 0.020002587), (2, 0.020010136), (3, 0.02000251), (4, 0.020003138), (5, 0.020003296), (6, 0.020001251), (7, 0.020003738), (8, 0.02000369), (9, 0.8199657)]\n",
      "[(0, 0.02000783), (1, 0.020001113), (2, 0.020008225), (3, 0.020022152), (4, 0.020007493), (5, 0.020007197), (6, 0.020003594), (7, 0.020011568), (8, 0.020001113), (9, 0.81992966)]\n"
     ]
    }
   ],
   "source": [
    "for doc in new_corpus[0:9]:\n",
    "    print(lda_new.get_document_topics(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85356b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -7.189317498732393\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', lda_new.log_perplexity(new_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8de35568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -7.189775884634407\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', lda_new.log_perplexity(new_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8db77700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import corpus2csc\n",
    "all_topics = lda_new.get_document_topics(new_corpus, minimum_probability=0.0)\n",
    "all_topics_csr = corpus2csc(all_topics)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()\n",
    "all_topics_df = pd.DataFrame(all_topics_numpy)\n",
    "\n",
    "classification_df = pd.concat([call_data, all_topics_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b0199fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PRES</th>\n",
       "      <th>TURN_AT_TALK</th>\n",
       "      <th>CEO</th>\n",
       "      <th>WORDCOUNT</th>\n",
       "      <th>Restatement Topic</th>\n",
       "      <th>FRAUD</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>556.500000</td>\n",
       "      <td>0.581688</td>\n",
       "      <td>15.447935</td>\n",
       "      <td>0.793537</td>\n",
       "      <td>18.205566</td>\n",
       "      <td>0.176840</td>\n",
       "      <td>0.352783</td>\n",
       "      <td>0.090717</td>\n",
       "      <td>0.083317</td>\n",
       "      <td>0.103588</td>\n",
       "      <td>0.119739</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>0.122571</td>\n",
       "      <td>0.092226</td>\n",
       "      <td>0.085626</td>\n",
       "      <td>0.079249</td>\n",
       "      <td>0.130325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>321.728405</td>\n",
       "      <td>0.493504</td>\n",
       "      <td>19.025057</td>\n",
       "      <td>0.404949</td>\n",
       "      <td>8.940149</td>\n",
       "      <td>0.381705</td>\n",
       "      <td>0.636108</td>\n",
       "      <td>0.212972</td>\n",
       "      <td>0.199048</td>\n",
       "      <td>0.230908</td>\n",
       "      <td>0.247129</td>\n",
       "      <td>0.215790</td>\n",
       "      <td>0.252661</td>\n",
       "      <td>0.213028</td>\n",
       "      <td>0.206871</td>\n",
       "      <td>0.193141</td>\n",
       "      <td>0.261410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>278.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>556.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.020010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>834.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033340</td>\n",
       "      <td>0.033339</td>\n",
       "      <td>0.033347</td>\n",
       "      <td>0.050002</td>\n",
       "      <td>0.033342</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.033341</td>\n",
       "      <td>0.033339</td>\n",
       "      <td>0.033338</td>\n",
       "      <td>0.050003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1113.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.935702</td>\n",
       "      <td>0.943745</td>\n",
       "      <td>0.939987</td>\n",
       "      <td>0.939993</td>\n",
       "      <td>0.949990</td>\n",
       "      <td>0.949983</td>\n",
       "      <td>0.930756</td>\n",
       "      <td>0.952621</td>\n",
       "      <td>0.935704</td>\n",
       "      <td>0.939993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         PRES  TURN_AT_TALK          CEO    WORDCOUNT  \\\n",
       "count  1114.000000  1114.000000   1114.000000  1114.000000  1114.000000   \n",
       "mean    556.500000     0.581688     15.447935     0.793537    18.205566   \n",
       "std     321.728405     0.493504     19.025057     0.404949     8.940149   \n",
       "min       0.000000     0.000000      2.000000     0.000000     1.000000   \n",
       "25%     278.250000     0.000000      3.000000     1.000000    12.000000   \n",
       "50%     556.500000     1.000000      4.000000     1.000000    17.000000   \n",
       "75%     834.750000     1.000000     24.000000     1.000000    23.000000   \n",
       "max    1113.000000     1.000000     93.000000     1.000000    62.000000   \n",
       "\n",
       "       Restatement Topic        FRAUD            0            1            2  \\\n",
       "count        1114.000000  1114.000000  1114.000000  1114.000000  1114.000000   \n",
       "mean            0.176840     0.352783     0.090717     0.083317     0.103588   \n",
       "std             0.381705     0.636108     0.212972     0.199048     0.230908   \n",
       "min             0.000000     0.000000     0.005264     0.005264     0.005264   \n",
       "25%             0.000000     0.000000     0.014287     0.014287     0.014288   \n",
       "50%             0.000000     0.000000     0.020003     0.020003     0.020005   \n",
       "75%             0.000000     1.000000     0.033340     0.033339     0.033347   \n",
       "max             1.000000     2.000000     0.935702     0.943745     0.939987   \n",
       "\n",
       "                 3            4            5            6            7  \\\n",
       "count  1114.000000  1114.000000  1114.000000  1114.000000  1114.000000   \n",
       "mean      0.119739     0.092642     0.122571     0.092226     0.085626   \n",
       "std       0.247129     0.215790     0.252661     0.213028     0.206871   \n",
       "min       0.005264     0.005264     0.005264     0.005264     0.005265   \n",
       "25%       0.014288     0.014288     0.014288     0.014287     0.014288   \n",
       "50%       0.020007     0.020004     0.020006     0.020003     0.020004   \n",
       "75%       0.050002     0.033342     0.050003     0.033341     0.033339   \n",
       "max       0.939993     0.949990     0.949983     0.930756     0.952621   \n",
       "\n",
       "                 8            9  \n",
       "count  1114.000000  1114.000000  \n",
       "mean      0.079249     0.130325  \n",
       "std       0.193141     0.261410  \n",
       "min       0.005264     0.005265  \n",
       "25%       0.014287     0.014288  \n",
       "50%       0.020003     0.020010  \n",
       "75%       0.033338     0.050003  \n",
       "max       0.935704     0.939993  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dbd7b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.32897711, 0.33165193, 0.32615852, 0.28246951, 0.27108026]), 'score_time': array([0.03889537, 0.03291225, 0.03089428, 0.0298543 , 0.02801657]), 'test_accuracy': array([0.84821429, 0.83928571, 0.79464286, 0.82142857, 0.76785714]), 'test_neg_log_loss': array([-1.0115674 , -0.40003523, -0.52848207, -0.76320408, -0.52950749]), 'test_f1': array([0.32      , 0.35714286, 0.20689655, 0.28571429, 0.13333333]), 'test_roc_auc': array([0.64076087, 0.72146739, 0.60516304, 0.63804348, 0.53777174])}\n",
      "Mean Accuracy: 0.8142857142857144\n",
      "Mean F1: 0.26061740558292285\n",
      "Mean ROC: 0.6286413043478262\n",
      "Mean Log Loss: -0.6465592533130089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "n_splits = 5\n",
    "\n",
    "pred_vars = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9,]\n",
    "\n",
    "\n",
    "scoring = ['accuracy', 'neg_log_loss', 'f1', 'roc_auc']\n",
    "rf_base = RandomForestClassifier()\n",
    "cv_rf = cross_validate(rf_base, classification_df[pred_vars], classification_df['Restatement Topic'], cv=StratifiedShuffleSplit(n_splits), scoring=scoring)\n",
    "print(cv_rf)\n",
    "print(\"Mean Accuracy:\", cv_rf['test_accuracy'].mean())\n",
    "print(\"Mean F1:\", cv_rf['test_f1'].mean())\n",
    "print(\"Mean ROC:\", cv_rf['test_roc_auc'].mean())\n",
    "print(\"Mean Log Loss:\", cv_rf['test_neg_log_loss'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0433a8c",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "1. Try fitting LDA with just 5 topics instead of 10. How does this affect human interpretability, perplexity, coherence, and classification performance?\n",
    "\n",
    "2. Try fitting LDA with 15 topics. How does this affect human interpretability, perplexity, coherence, and classification performance?\n",
    "\n",
    "3. In addition to Random Forest, try another classifier of your choosing. How does this compare to the Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5e145",
   "metadata": {},
   "source": [
    "# Optional Tasks\n",
    "\n",
    "1. Run sentiment analysis on this data. Does adding that to a classifier improve performance?\n",
    "\n",
    "2. See the section below on weighted word counts. Does using tf-idf improve human interpretability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5275a36",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Try fitting LDA with just 5 topics instead of 10. How does this affect human interpretability, perplexity, coherence, and classification performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d7e08bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 : 0.018*\"continu\" + 0.015*\"gener\" + 0.013*\"activ\" + 0.013*\"tubular\" + 0.012*\"share\" + 0.011*\"pipe\" + 0.011*\"month\" + 0.009*\"effect\" + 0.009*\"opportun\" + 0.009*\"facil\"\n",
      "Topic 1 : 0.020*\"certainli\" + 0.014*\"compar\" + 0.013*\"continu\" + 0.013*\"group\" + 0.012*\"tubular\" + 0.011*\"strong\" + 0.010*\"share\" + 0.009*\"water\" + 0.009*\"rang\" + 0.009*\"transmiss\"\n",
      "Topic 2 : 0.027*\"project\" + 0.024*\"water\" + 0.019*\"result\" + 0.018*\"transmiss\" + 0.015*\"group\" + 0.014*\"compar\" + 0.014*\"tubular\" + 0.013*\"steel\" + 0.012*\"signific\" + 0.012*\"improv\"\n",
      "Topic 3 : 0.032*\"steel\" + 0.025*\"project\" + 0.014*\"water\" + 0.014*\"higher\" + 0.013*\"continu\" + 0.011*\"issu\" + 0.010*\"result\" + 0.010*\"fund\" + 0.009*\"tubular\" + 0.009*\"work\"\n",
      "Topic 4 : 0.020*\"steel\" + 0.017*\"project\" + 0.016*\"bid\" + 0.013*\"job\" + 0.012*\"probabl\" + 0.010*\"half\" + 0.010*\"backlog\" + 0.010*\"order\" + 0.010*\"book\" + 0.009*\"strong\"\n"
     ]
    }
   ],
   "source": [
    "lda_new_2 = models.LdaModel(new_corpus, num_topics=5, id2word=new_dictionary)\n",
    "\n",
    "for topic in lda_new_2.show_topics():\n",
    "    print(\"Topic\", topic[0], \":\", topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d1de343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.100018024), (1, 0.10001767), (2, 0.10001352), (3, 0.10001732), (4, 0.5999335)]\n",
      "[(0, 0.8846291), (1, 0.028796803), (2, 0.02869406), (3, 0.029197399), (4, 0.028682638)]\n",
      "[(0, 0.015563075), (1, 0.9380681), (2, 0.015483566), (3, 0.015487208), (4, 0.015398054)]\n",
      "[(0, 0.022292644), (1, 0.022265011), (2, 0.91069597), (3, 0.0224084), (4, 0.022337934)]\n",
      "[(0, 0.01676031), (1, 0.016768405), (2, 0.017041635), (3, 0.9326322), (4, 0.016797446)]\n"
     ]
    }
   ],
   "source": [
    "for doc in new_corpus[0:5]:\n",
    "    print(lda_new_2.get_document_topics(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddb0c74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -6.915479806325692\n",
      "Perplexity:  -6.915510124540565\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', lda_new_2.log_perplexity(new_corpus))\n",
    "print('Perplexity: ', lda_new_2.log_perplexity(new_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "580bde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = lda_new_2.get_document_topics(new_corpus, minimum_probability=0.0)\n",
    "all_topics_csr = corpus2csc(all_topics)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()\n",
    "all_topics_df = pd.DataFrame(all_topics_numpy)\n",
    "\n",
    "classification_df = pd.concat([call_data, all_topics_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efc1e50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PRES</th>\n",
       "      <th>TURN_AT_TALK</th>\n",
       "      <th>CEO</th>\n",
       "      <th>WORDCOUNT</th>\n",
       "      <th>Restatement Topic</th>\n",
       "      <th>FRAUD</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>556.500000</td>\n",
       "      <td>0.581688</td>\n",
       "      <td>15.447935</td>\n",
       "      <td>0.793537</td>\n",
       "      <td>18.205566</td>\n",
       "      <td>0.176840</td>\n",
       "      <td>0.352783</td>\n",
       "      <td>0.192191</td>\n",
       "      <td>0.189635</td>\n",
       "      <td>0.262094</td>\n",
       "      <td>0.181297</td>\n",
       "      <td>0.174783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>321.728405</td>\n",
       "      <td>0.493504</td>\n",
       "      <td>19.025057</td>\n",
       "      <td>0.404949</td>\n",
       "      <td>8.940149</td>\n",
       "      <td>0.381705</td>\n",
       "      <td>0.636108</td>\n",
       "      <td>0.292925</td>\n",
       "      <td>0.288929</td>\n",
       "      <td>0.336938</td>\n",
       "      <td>0.283981</td>\n",
       "      <td>0.275034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011254</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>0.010602</td>\n",
       "      <td>0.010593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>278.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029156</td>\n",
       "      <td>0.029162</td>\n",
       "      <td>0.033711</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.028844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>556.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050190</td>\n",
       "      <td>0.050116</td>\n",
       "      <td>0.066689</td>\n",
       "      <td>0.050210</td>\n",
       "      <td>0.050009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>834.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.103502</td>\n",
       "      <td>0.589466</td>\n",
       "      <td>0.101337</td>\n",
       "      <td>0.100800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1113.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.956876</td>\n",
       "      <td>0.952416</td>\n",
       "      <td>0.954606</td>\n",
       "      <td>0.952467</td>\n",
       "      <td>0.948753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         PRES  TURN_AT_TALK          CEO    WORDCOUNT  \\\n",
       "count  1114.000000  1114.000000   1114.000000  1114.000000  1114.000000   \n",
       "mean    556.500000     0.581688     15.447935     0.793537    18.205566   \n",
       "std     321.728405     0.493504     19.025057     0.404949     8.940149   \n",
       "min       0.000000     0.000000      2.000000     0.000000     1.000000   \n",
       "25%     278.250000     0.000000      3.000000     1.000000    12.000000   \n",
       "50%     556.500000     1.000000      4.000000     1.000000    17.000000   \n",
       "75%     834.750000     1.000000     24.000000     1.000000    23.000000   \n",
       "max    1113.000000     1.000000     93.000000     1.000000    62.000000   \n",
       "\n",
       "       Restatement Topic        FRAUD            0            1            2  \\\n",
       "count        1114.000000  1114.000000  1114.000000  1114.000000  1114.000000   \n",
       "mean            0.176840     0.352783     0.192191     0.189635     0.262094   \n",
       "std             0.381705     0.636108     0.292925     0.288929     0.336938   \n",
       "min             0.000000     0.000000     0.011254     0.010628     0.010950   \n",
       "25%             0.000000     0.000000     0.029156     0.029162     0.033711   \n",
       "50%             0.000000     0.000000     0.050190     0.050116     0.066689   \n",
       "75%             0.000000     1.000000     0.103083     0.103502     0.589466   \n",
       "max             1.000000     2.000000     0.956876     0.952416     0.954606   \n",
       "\n",
       "                 3            4  \n",
       "count  1114.000000  1114.000000  \n",
       "mean      0.181297     0.174783  \n",
       "std       0.283981     0.275034  \n",
       "min       0.010602     0.010593  \n",
       "25%       0.029444     0.028844  \n",
       "50%       0.050210     0.050009  \n",
       "75%       0.101337     0.100800  \n",
       "max       0.952467     0.948753  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45986c",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Try fitting LDA with 15 topics. How does this affect human interpretability, perplexity, coherence, and classification performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b72c0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Topic 0 : 0.026*\"steel\" + 0.020*\"materi\" + 0.017*\"work\" + 0.013*\"statement\" + 0.013*\"rule\" + 0.012*\"total\" + 0.010*\"pipelin\" + 0.010*\"season\" + 0.010*\"final\" + 0.010*\"project\"\n",
      "Topic 5 : 0.019*\"construct\" + 0.019*\"job\" + 0.019*\"ahead\" + 0.016*\"opportun\" + 0.016*\"profit\" + 0.016*\"gross\" + 0.016*\"compar\" + 0.013*\"record\" + 0.013*\"certainli\" + 0.013*\"project\"\n",
      "Topic 14 : 0.016*\"spend\" + 0.016*\"group\" + 0.016*\"compar\" + 0.014*\"demand\" + 0.014*\"tubular\" + 0.014*\"earn\" + 0.014*\"pipe\" + 0.012*\"econom\" + 0.012*\"activ\" + 0.012*\"higher\"\n",
      "Topic 7 : 0.037*\"share\" + 0.017*\"facil\" + 0.016*\"certainli\" + 0.013*\"believ\" + 0.013*\"ye\" + 0.013*\"dilut\" + 0.013*\"project\" + 0.013*\"improv\" + 0.011*\"effect\" + 0.010*\"volum\"\n",
      "Topic 8 : 0.024*\"high\" + 0.019*\"continu\" + 0.018*\"gener\" + 0.017*\"cash\" + 0.017*\"record\" + 0.014*\"flow\" + 0.014*\"financ\" + 0.013*\"half\" + 0.013*\"stronger\" + 0.011*\"capac\"\n",
      "Topic 3 : 0.032*\"project\" + 0.022*\"brian\" + 0.021*\"result\" + 0.017*\"financi\" + 0.015*\"stephani\" + 0.013*\"backlog\" + 0.012*\"steel\" + 0.010*\"review\" + 0.010*\"activ\" + 0.010*\"volum\"\n",
      "Topic 13 : 0.045*\"steel\" + 0.025*\"backlog\" + 0.020*\"result\" + 0.018*\"higher\" + 0.014*\"share\" + 0.014*\"capit\" + 0.011*\"order\" + 0.011*\"earn\" + 0.011*\"compar\" + 0.010*\"gener\"\n",
      "Topic 11 : 0.023*\"inventori\" + 0.023*\"energi\" + 0.023*\"probabl\" + 0.017*\"certainli\" + 0.017*\"steel\" + 0.014*\"todai\" + 0.014*\"pipe\" + 0.012*\"project\" + 0.011*\"statement\" + 0.011*\"differ\"\n",
      "Topic 1 : 0.026*\"bid\" + 0.026*\"order\" + 0.023*\"steel\" + 0.020*\"forecast\" + 0.018*\"stimulu\" + 0.018*\"project\" + 0.015*\"base\" + 0.013*\"stephani\" + 0.012*\"continu\" + 0.012*\"averag\"\n",
      "Topic 4 : 0.017*\"steel\" + 0.014*\"financi\" + 0.012*\"averag\" + 0.012*\"continu\" + 0.012*\"abl\" + 0.012*\"suppli\" + 0.012*\"backlog\" + 0.009*\"tax\" + 0.009*\"crisi\" + 0.009*\"current\"\n"
     ]
    }
   ],
   "source": [
    "lda_new_3 = models.LdaModel(new_corpus, num_topics=15, id2word=new_dictionary)\n",
    "print(len(lda_new_3.show_topics()))\n",
    "for topic in lda_new_3.show_topics():\n",
    "    #print()\n",
    "    print(\"Topic\", topic[0], \":\", topic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3da4896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[(59, 0.20173945), (64, 0.20173071), (65, 0.40174204)]\n",
      "[(74, 0.9237454)]\n",
      "[(95, 0.88985485)]\n",
      "[(85, 0.917391)]\n",
      "[(71, 0.16811103), (74, 0.33478427), (95, 0.33478236)]\n",
      "[]\n",
      "[(8, 0.40173888), (112, 0.40173793)]\n",
      "[(53, 0.40173823), (95, 0.2017382), (100, 0.20173827)]\n",
      "[(15, 0.41099524), (41, 0.22673966), (104, 0.1674804)]\n",
      "[(0, 0.20173413), (4, 0.20173587), (7, 0.20173953), (100, 0.20174143)]\n",
      "[(79, 0.75217265)]\n",
      "[(101, 0.87608624)]\n",
      "[(43, 0.14409594), (53, 0.14409423), (57, 0.36274603), (82, 0.21117201)]\n",
      "[(12, 0.2017379), (79, 0.6017388)]\n"
     ]
    }
   ],
   "source": [
    "for doc in new_corpus[0:15]:\n",
    "    print(lda_new_3.get_document_topics(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fc8dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -17.58528391814902\n",
      "Perplexity:  -17.591051012004588\n"
     ]
    }
   ],
   "source": [
    "print('Perplexity: ', lda_new_3.log_perplexity(new_corpus))\n",
    "print('Perplexity: ', lda_new_3.log_perplexity(new_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d22afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = lda_new_3.get_document_topics(new_corpus, minimum_probability=0.0)\n",
    "all_topics_csr = corpus2csc(all_topics)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()\n",
    "all_topics_df = pd.DataFrame(all_topics_numpy)\n",
    "\n",
    "classification_df = pd.concat([call_data, all_topics_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4860c64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PRES</th>\n",
       "      <th>TURN_AT_TALK</th>\n",
       "      <th>CEO</th>\n",
       "      <th>WORDCOUNT</th>\n",
       "      <th>Restatement Topic</th>\n",
       "      <th>FRAUD</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "      <td>1114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>556.500000</td>\n",
       "      <td>0.581688</td>\n",
       "      <td>15.447935</td>\n",
       "      <td>0.793537</td>\n",
       "      <td>18.205566</td>\n",
       "      <td>0.176840</td>\n",
       "      <td>0.352783</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.011510</td>\n",
       "      <td>0.002491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>321.728405</td>\n",
       "      <td>0.493504</td>\n",
       "      <td>19.025057</td>\n",
       "      <td>0.404949</td>\n",
       "      <td>8.940149</td>\n",
       "      <td>0.381705</td>\n",
       "      <td>0.636108</td>\n",
       "      <td>0.063327</td>\n",
       "      <td>0.068459</td>\n",
       "      <td>0.043343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042019</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.058568</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.062102</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.064986</td>\n",
       "      <td>0.071829</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>278.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.001242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>556.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>834.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.002899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1113.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.929192</td>\n",
       "      <td>0.929192</td>\n",
       "      <td>0.900869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944927</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.938043</td>\n",
       "      <td>0.876086</td>\n",
       "      <td>0.876087</td>\n",
       "      <td>0.900869</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.889855</td>\n",
       "      <td>0.909881</td>\n",
       "      <td>0.008696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         PRES  TURN_AT_TALK          CEO    WORDCOUNT  \\\n",
       "count  1114.000000  1114.000000   1114.000000  1114.000000  1114.000000   \n",
       "mean    556.500000     0.581688     15.447935     0.793537    18.205566   \n",
       "std     321.728405     0.493504     19.025057     0.404949     8.940149   \n",
       "min       0.000000     0.000000      2.000000     0.000000     1.000000   \n",
       "25%     278.250000     0.000000      3.000000     1.000000    12.000000   \n",
       "50%     556.500000     1.000000      4.000000     1.000000    17.000000   \n",
       "75%     834.750000     1.000000     24.000000     1.000000    23.000000   \n",
       "max    1113.000000     1.000000     93.000000     1.000000    62.000000   \n",
       "\n",
       "       Restatement Topic        FRAUD            0            1            2  \\\n",
       "count        1114.000000  1114.000000  1114.000000  1114.000000  1114.000000   \n",
       "mean            0.176840     0.352783     0.008647     0.010351     0.007017   \n",
       "std             0.381705     0.636108     0.063327     0.068459     0.043343   \n",
       "min             0.000000     0.000000     0.000458     0.000458     0.000458   \n",
       "25%             0.000000     0.000000     0.001242     0.001242     0.001242   \n",
       "50%             0.000000     0.000000     0.001739     0.001739     0.001739   \n",
       "75%             0.000000     1.000000     0.002899     0.002899     0.002899   \n",
       "max             1.000000     2.000000     0.929192     0.929192     0.900869   \n",
       "\n",
       "       ...          105          106          107          108          109  \\\n",
       "count  ...  1114.000000  1114.000000  1114.000000  1114.000000  1114.000000   \n",
       "mean   ...     0.005381     0.002491     0.009703     0.009925     0.004486   \n",
       "std    ...     0.042019     0.001988     0.059322     0.058568     0.032857   \n",
       "min    ...     0.000458     0.000458     0.000458     0.000458     0.000458   \n",
       "25%    ...     0.001242     0.001242     0.001242     0.001242     0.001242   \n",
       "50%    ...     0.001739     0.001739     0.001739     0.001739     0.001739   \n",
       "75%    ...     0.002899     0.002899     0.002899     0.002899     0.002899   \n",
       "max    ...     0.944927     0.008696     0.938043     0.876086     0.876087   \n",
       "\n",
       "               110          111          112          113          114  \n",
       "count  1114.000000  1114.000000  1114.000000  1114.000000  1114.000000  \n",
       "mean      0.010750     0.002491     0.010878     0.011510     0.002491  \n",
       "std       0.062102     0.001988     0.064986     0.071829     0.001988  \n",
       "min       0.000458     0.000458     0.000458     0.000458     0.000458  \n",
       "25%       0.001242     0.001242     0.001242     0.001242     0.001242  \n",
       "50%       0.001739     0.001739     0.001739     0.001739     0.001739  \n",
       "75%       0.002899     0.002899     0.002899     0.002899     0.002899  \n",
       "max       0.900869     0.008696     0.889855     0.909881     0.008696  \n",
       "\n",
       "[8 rows x 122 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a806f1",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "In addition to Random Forest, try another classifier of your choosing. How does this compare to the Random Forest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa933e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
